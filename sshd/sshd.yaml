# Configuration of the keys that can connect to the server.
# You should add the public keys (usually ~/.ssh/id_rsa.pub) for each user/machine that can use this tunnel.
# See docs around 'authorized_keys' for how this works.
#apiVersion: v1
#kind: ConfigMap
#metadata:
#  name: sshd
#  labels:
#    app: sshd
#data:
#  authorized_keys: |
#    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC7wemKmbW6s3bk8XSEEM3dCnSqzIrHhYuCpCguFJhKubCpBa/XYbRbCLtuw4uNMSNwOusiePd+9YkRrZl4G1+miG/eWY30GEXmK6Lf0ovhLGRQj5uRbSwsR775N6A+if8b6703UCeWaklcK9NSMEH0hqwhGBJMT+fq335V2mIzANTn588ae+6jgVBAUSD/xt9BusJPz7izQ1kTG2Q2Djd7CXW1uUXuuztZoHpL8Mec23kQPX/tzHeDg+vZaXdzPhUW22YH5paVDldW5+kBqWeyxjD30SV5yfPgM0pjrUWllhlfhd7lee17qQno/rlmGgahlpjhw7XhwDZ5VTWI7+8G0GqZ6AE8xC9Vw9aslaNqiGNL9Sj4yiOUPvNmgN1p7XlYGPTLYtDGvctzsGqIsM/8lUsTodtFmb0CTyE6uV5JYdjQyTyLnCTbB1dfV8AZZDixVj6Mpjv/9rJhvY2sevntpnqttozULYBLXotTEGLnycowp6qe3u+Nap178GoYjWM= jacky_li@Jackys-MacBook-Pro.local

#---
# An example LoadBalancer service.
# On EKS or GKE this should automatically create a public hostname where sshd can be reached.
# You can use something else like an Ingress if needed.
#apiVersion: v1
#kind: Service
#metadata:
#  name: sshd-lb
#spec:
#  type: LoadBalancer
#  ports:
#  - name: ssh
#    port: 22
#    targetPort: ssh
#  selector:
#    app: sshd
---
# Standard service, can be used for an ingress or similar.
apiVersion: v1
kind: Service
metadata:
  name: sshd
spec:
  ports:
  - name: ssh
    port: 22
    targetPort: ssh
  selector:
    app: sshd
---
# The sshd pod itself is run via this StatefulSet.
# Note that with some additional customization you could run multiple of these for different users.
# But don't just increase the replicas - that will lead to mismatched server keys across the replicas.
# The persistent volume is used for preserving randomly server keys that are generated on first launch.
# If the persistent volume is destroyed then clients will get a warning about mismatched keys when they next connect.
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sshd
  labels:
    app: sshd
spec:
  serviceName: sshd
  # Just run one instance - if multiple instances run then they will each have different keys.
  replicas: 1
  selector:
    matchLabels:
      app: sshd
  template:
    metadata:
      labels:
        app: sshd
    spec:
      containers:
      - name: sshd
        # This image is based on https://github.com/linuxserver/docker-openssh-server
        # The only modification is the installation of python3, as required by sshuttle.
        # See docker/Dockerfile.
        image: linuxserver/openssh-server:latest
        # This manual command ensures that authorized_keys is synced every time.
        # Otherwise the base image ignores new keys if the file already exists.
        command:
        - /bin/sh
        - -c
        - apk update && apk add python3 && rm -f /config/.ssh/authorized_keys && /init
        # The following envvars configure the openssh daemon. A list of settings can be found here:
        # https://github.com/linuxserver/docker-openssh-server#parameters
        env:
        # OPTIONAL: You may customize the username to use when connecting to this ssh server.
        #           All users will access the cluster via this username.
        - name: USER_NAME
          value: tunnel
        # Where the configmap data is located. This is copied into /config/.ssh/authorized_keys on pod start.
        - name: PUBLIC_KEY_FILE
          value: /keys-ro/authorized_keys
        # After init, the sshd process will run as nobody:nobody (on port 2222)
        - name: PUID
          value: "65534" # uid:nobody
        - name: PGID
          value: "65534" # gid:nobody
        volumeMounts:
        - name: keys
          mountPath: /keys-ro
          readOnly: true
        - name: data
          mountPath: /config
        ports:
        - name: ssh
          containerPort: 2222
        readinessProbe:
          tcpSocket:
            port: 2222
      volumes:
      - name: keys
        secret:
          secretName: sshd-authorized-keys
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 100Mi